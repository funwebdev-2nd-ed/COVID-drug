{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "We finetuned Cardiff's [twitter-roberta-base-sentiment](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment) model on the [COVID-CQ dataset](https://github.com/eceveco/COVID-CQ). We downloaded the data and put it in the data/ directory. We clean up urls before training. We trained two models, one with drug names masked and one without. The latter one performed better on our dataset, but we provide the method to train both models. Also, the COVID-CQ includes tweets that mention either Choloroquine or Hydroxychloroquine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 48 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14374"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "stance = pd.read_csv(\"data/HCQ.csv\")\n",
    "len(stance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_url(x):\n",
    "    return re.sub(r\"http\\S+\",\"\", x)\n",
    "stance.text = stance.text.apply(lambda x: clean_url(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14365"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stance = stance[[\"text\",\"stance\"]].dropna(subset=[\"stance\"])\n",
    "stance.stance = stance.stance.astype(int)\n",
    "len(stance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetune bert\n",
    "Beginners could follow this [tutorial](https://medium.com/nerd-for-tech/fine-tuning-pretrained-bert-for-sentiment-classification-using-transformers-in-python-931ed142e37).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(stance.text.values, stance.stance.values, test_size=0.2, random_state=42)\n",
    "# X_train, X_dev, y_train, y_dev = train_test_split(X_train.tolist(), y_train.tolist(), test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 616.,    0.,    0.,  897.,    0., 1360.]),\n",
       " array([0.        , 0.33333333, 0.66666667, 1.        , 1.33333333,\n",
       "        1.66666667, 2.        ]),\n",
       " <BarContainer object of 6 artists>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## Check that train and test have similar distribution.\n",
    "plt.hist(y_test, bins=6, density=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set patterns to extract from tweets\n",
    "keywords_dict = {\"hcq\":\"ydroxych| hcq |plaqu |plaquenil|hydroquin|axemal\",\n",
    "                \"ivermectin\": \"ivermectin|stromectol|soolantra|sklice\",\n",
    "                \"remdesivir\": \"remdesivir|veklury\",\n",
    "                \"molnupiravir\": \"molnupiravir|merck's drug|merck's pill|merck's antiviral\"}\n",
    "\n",
    "tobe_masked = [ i.strip() for i in keywords_dict[\"hcq\"].split(\"|\")]\n",
    "\n",
    "def mask(x):\n",
    "    for w in tobe_masked:\n",
    "        if w in x:\n",
    "            return \"[mask]\"\n",
    "    return x\n",
    "\n",
    "def m(sent):\n",
    "    new_sent = []\n",
    "    sent = sent.lower().split(\" \")\n",
    "    for word in sent:\n",
    "        new_sent.append(mask(word))\n",
    "    return \" \".join(new_sent)\n",
    "\n",
    "X_train_df = pd.DataFrame(X_test)\n",
    "masked = X_train_df[0].parallel_apply(lambda x: m(x)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/config.json from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/7dd97280b5338fb674b5372829a05a1aaaa76f9f2fa71c36199f2ce1ee1104a0.4c7ca95b4fd82b8bbe94fde253f5f82e5a4eedefe6f86f6fa79efc903d6cfe60\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"tweeteval_new/roberta-base-rt-sentiment/\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/vocab.json from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/089d0f043cfdb86b4f4d79238552b1dcd5b791d4be7c48f27bd7323bdbb7c599.647b4548b6d9ea817e82e7a9231a320231a1c9ea24053cc9e758f3fe68216f05\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/merges.txt from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/45449f1b6476a9fe84f9eade7f45745cdea8af6b3735f760d8bb0f4b71adf57f.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/special_tokens_map.json from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/5d7665586d1ae04ace347574fee8f19ad7875acf296e81464f2fb0bb70c0c404.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/config.json from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/7dd97280b5338fb674b5372829a05a1aaaa76f9f2fa71c36199f2ce1ee1104a0.4c7ca95b4fd82b8bbe94fde253f5f82e5a4eedefe6f86f6fa79efc903d6cfe60\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"tweeteval_new/roberta-base-rt-sentiment/\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/config.json from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/7dd97280b5338fb674b5372829a05a1aaaa76f9f2fa71c36199f2ce1ee1104a0.4c7ca95b4fd82b8bbe94fde253f5f82e5a4eedefe6f86f6fa79efc903d6cfe60\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"tweeteval_new/roberta-base-rt-sentiment/\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "# MODEL = \"rabindralamsal/finetuned-bertweet-sentiment-analysis\"\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True,return_tensors = 'pt')\n",
    "# dev_encodings = tokenizer(X_dev, truncation=True, padding=True,return_tensors = 'pt')\n",
    "test_encodings = tokenizer(masked, truncation=True, padding=True,return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11492"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    ## Test Dataset\n",
    "class SentimentTestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SentimentDataset(train_encodings, y_train)\n",
    "dev_dataset = SentimentDataset(dev_encodings, y_test)\n",
    "test_dataset = SentimentDataset(test_encodings, y_test)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8)\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/config.json from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/7dd97280b5338fb674b5372829a05a1aaaa76f9f2fa71c36199f2ce1ee1104a0.4c7ca95b4fd82b8bbe94fde253f5f82e5a4eedefe6f86f6fa79efc903d6cfe60\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"tweeteval_new/roberta-base-rt-sentiment/\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment/resolve/main/pytorch_model.bin from cache at /mnt/hdd/ningh/.cache/huggingface/transformers/11065c9c045391e7a6b2bb2451b862074866aeddabaece3ef767540b48247a1c.a8b67614ee564f9fefd65a3a42566038ccf3e86668cb888d8ae05ec670696ba7\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL, num_labels=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 8\n",
    "# import numpy as np\n",
    "# from datasets import load_metric\n",
    "\n",
    "# metric = load_metric(\"recall\")\n",
    "\n",
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# from transformers import TrainingArguments\n",
    "# args = TrainingArguments(\n",
    "#     f\"drug-stance-bert\",\n",
    "#     evaluation_strategy = \"epoch\",\n",
    "#     save_strategy = \"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=batch_size,\n",
    "#     per_device_eval_batch_size=batch_size,\n",
    "#     num_train_epochs=5,\n",
    "#     weight_decay=0.01,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"accuracy\",\n",
    "#     # push_to_hub=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model,\n",
    "#     args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=dev_dataset,\n",
    "#     tokenizer=tokenizer,\n",
    "#     compute_metrics=compute_metrics)\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd794b92f5b44f68fa25318ab1d7906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4311 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-54-15798f005e27>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-15798f005e27>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8350156630699617}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")\n",
    "model.eval()\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(\"cuda:1\") for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/enchome/anaconda3/envs/twee/lib/python3.9/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Configuration saved in model/Twitter-drug-stance-bert-masked/config.json\n",
      "Model weights saved in model/Twitter-drug-stance-bert-masked/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "# model.push_to_hub(\"drug-stance-bert\", organization=\"MTERMS\")\n",
    "model.save_pretrained(\"model/Twitter-drug-stance-bert-masked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
