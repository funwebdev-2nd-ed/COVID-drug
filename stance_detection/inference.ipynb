{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1aca8c66",
   "metadata": {},
   "source": [
    "### Remove tweets with more than one drug\n",
    "\n",
    "The model was trained on HCQ data, and we used the unmasked model for inference. So we need to remove tweets with multiple drug names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3154e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# dfs = []\n",
    "# for file in glob.glob(\"../data/final/*.csv\"):\n",
    "#     df = pd.read_csv(file)[[\"wave\",\"stance\"]].value_counts().reset_index().sort_values([\"wave\",\"stance\"]).reset_index(drop=True)\n",
    "#     df[\"drug\"] = file.split(\"/\")[-1].split(\".csv\")[0]\n",
    "#     dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa46b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)\n",
    "df = df.sort_values([\"drug\",\"wave\",\"stance\"])\n",
    "dfs = []\n",
    "for n,g in df.groupby([\"drug\",\"wave\"]):\n",
    "    s = g[0].sum()\n",
    "    g[\"ratio\"] = g[0]/s\n",
    "    dfs.append(g.reset_index())\n",
    "df = pd.concat(dfs)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"distribution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb409c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drug = df.drug.replace(\"hcq\",\"Hydroxychloroquine\")\n",
    "df.drug = df.drug.replace(\"ivermectin\",\"Ivermectin\")\n",
    "df.drug = df.drug.replace(\"molnupiravir\",\"Molnupiravir\")\n",
    "df.drug = df.drug.replace(\"remdesivir\",\"Remdesivir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8352838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Count\"] = df.pop(\"level_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5db1378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wave</th>\n",
       "      <th>stance</th>\n",
       "      <th>drug</th>\n",
       "      <th>ratio</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.350514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.138435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.511050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.328862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.133797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.537341</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.320499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Hydroxychloroquine</td>\n",
       "      <td>0.543065</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.123950</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.223319</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.652731</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.137527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.219025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.643448</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.369823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.194619</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Ivermectin</td>\n",
       "      <td>0.435558</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.127690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.355811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.516499</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.143363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.328531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Molnupiravir</td>\n",
       "      <td>0.528106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.151766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.391489</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.456745</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.330130</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.236421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.433449</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.374629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.187402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Remdesivir</td>\n",
       "      <td>0.437969</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wave  stance                drug     ratio  Count\n",
       "0      1      -1  Hydroxychloroquine  0.350514      0\n",
       "1      1       0  Hydroxychloroquine  0.138435      1\n",
       "2      1       1  Hydroxychloroquine  0.511050      2\n",
       "3      2      -1  Hydroxychloroquine  0.328862      0\n",
       "4      2       0  Hydroxychloroquine  0.133797      1\n",
       "5      2       1  Hydroxychloroquine  0.537341      2\n",
       "6      3      -1  Hydroxychloroquine  0.320499      0\n",
       "7      3       0  Hydroxychloroquine  0.136435      1\n",
       "8      3       1  Hydroxychloroquine  0.543065      2\n",
       "9      1      -1          Ivermectin  0.123950      0\n",
       "10     1       0          Ivermectin  0.223319      1\n",
       "11     1       1          Ivermectin  0.652731      2\n",
       "12     2      -1          Ivermectin  0.137527      0\n",
       "13     2       0          Ivermectin  0.219025      1\n",
       "14     2       1          Ivermectin  0.643448      2\n",
       "15     3      -1          Ivermectin  0.369823      0\n",
       "16     3       0          Ivermectin  0.194619      1\n",
       "17     3       1          Ivermectin  0.435558      2\n",
       "18     1      -1        Molnupiravir  0.208333      0\n",
       "19     1       0        Molnupiravir  0.416667      1\n",
       "20     1       1        Molnupiravir  0.375000      2\n",
       "21     2      -1        Molnupiravir  0.127690      0\n",
       "22     2       0        Molnupiravir  0.355811      1\n",
       "23     2       1        Molnupiravir  0.516499      2\n",
       "24     3      -1        Molnupiravir  0.143363      0\n",
       "25     3       0        Molnupiravir  0.328531      1\n",
       "26     3       1        Molnupiravir  0.528106      2\n",
       "27     1      -1          Remdesivir  0.151766      0\n",
       "28     1       0          Remdesivir  0.391489      1\n",
       "29     1       1          Remdesivir  0.456745      2\n",
       "30     2      -1          Remdesivir  0.330130      0\n",
       "31     2       0          Remdesivir  0.236421      1\n",
       "32     2       1          Remdesivir  0.433449      2\n",
       "33     3      -1          Remdesivir  0.374629      0\n",
       "34     3       0          Remdesivir  0.187402      1\n",
       "35     3       1          Remdesivir  0.437969      2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "947db807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat(dfs)\n",
    "# dfs = []\n",
    "# for n,g in df.groupby([\"Drug\",\"Wave\"]):\n",
    "#     g = g.sort_values(\"Stance\",ascending=True)\n",
    "#     dfs.append(g.reset_index())\n",
    "# df = pd.concat(dfs)\n",
    "# d={-1:\"Negative\",\n",
    "# 0:\"Neutral\",\n",
    "# 1:\"Positive\"}\n",
    "# def map_stance(x):\n",
    "#     return d[x]\n",
    "# df.Stance=df.Stance.apply(lambda x: map_stance(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a8651ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Number of tweets\"] = df.pop(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c8b316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.pop(\"index\")\n",
    "df.columns = [c.capitalize() for c in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "338cf65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f242836bc9a041d3bed17eafd3f10a5b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f242836bc9a041d3bed17eafd3f10a5b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f242836bc9a041d3bed17eafd3f10a5b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-b37a78632346a2b232e2c019ace87781\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"Stance\", \"scale\": {\"domain\": [-1, 0, 1], \"range\": [\"#fd7f6f\", \"#cfd8dc\", \"#7e9ab9\"]}, \"type\": \"nominal\"}, \"column\": {\"field\": \"Drug\", \"type\": \"nominal\"}, \"opacity\": {\"value\": 0.9}, \"x\": {\"field\": \"Wave\", \"type\": \"ordinal\"}, \"y\": {\"field\": \"Ratio\", \"type\": \"quantitative\"}}, \"height\": 150, \"width\": 60, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-b37a78632346a2b232e2c019ace87781\": [{\"Wave\": 1, \"Stance\": -1, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.3505141317906894, \"Count\": 0}, {\"Wave\": 1, \"Stance\": 0, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.1384353893635103, \"Count\": 1}, {\"Wave\": 1, \"Stance\": 1, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.5110504788458002, \"Count\": 2}, {\"Wave\": 2, \"Stance\": -1, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.3288618563572738, \"Count\": 0}, {\"Wave\": 2, \"Stance\": 0, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.133797144920291, \"Count\": 1}, {\"Wave\": 2, \"Stance\": 1, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.5373409987224351, \"Count\": 2}, {\"Wave\": 3, \"Stance\": -1, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.3204993705413344, \"Count\": 0}, {\"Wave\": 3, \"Stance\": 0, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.1364351657574486, \"Count\": 1}, {\"Wave\": 3, \"Stance\": 1, \"Drug\": \"Hydroxychloroquine\", \"Ratio\": 0.543065463701217, \"Count\": 2}, {\"Wave\": 1, \"Stance\": -1, \"Drug\": \"Ivermectin\", \"Ratio\": 0.1239495798319327, \"Count\": 0}, {\"Wave\": 1, \"Stance\": 0, \"Drug\": \"Ivermectin\", \"Ratio\": 0.2233193277310924, \"Count\": 1}, {\"Wave\": 1, \"Stance\": 1, \"Drug\": \"Ivermectin\", \"Ratio\": 0.6527310924369748, \"Count\": 2}, {\"Wave\": 2, \"Stance\": -1, \"Drug\": \"Ivermectin\", \"Ratio\": 0.137527366963049, \"Count\": 0}, {\"Wave\": 2, \"Stance\": 0, \"Drug\": \"Ivermectin\", \"Ratio\": 0.2190250659041151, \"Count\": 1}, {\"Wave\": 2, \"Stance\": 1, \"Drug\": \"Ivermectin\", \"Ratio\": 0.6434475671328359, \"Count\": 2}, {\"Wave\": 3, \"Stance\": -1, \"Drug\": \"Ivermectin\", \"Ratio\": 0.3698228218867663, \"Count\": 0}, {\"Wave\": 3, \"Stance\": 0, \"Drug\": \"Ivermectin\", \"Ratio\": 0.1946188518304117, \"Count\": 1}, {\"Wave\": 3, \"Stance\": 1, \"Drug\": \"Ivermectin\", \"Ratio\": 0.435558326282822, \"Count\": 2}, {\"Wave\": 1, \"Stance\": -1, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.2083333333333333, \"Count\": 0}, {\"Wave\": 1, \"Stance\": 0, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.4166666666666667, \"Count\": 1}, {\"Wave\": 1, \"Stance\": 1, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.375, \"Count\": 2}, {\"Wave\": 2, \"Stance\": -1, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.127690100430416, \"Count\": 0}, {\"Wave\": 2, \"Stance\": 0, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.3558106169296987, \"Count\": 1}, {\"Wave\": 2, \"Stance\": 1, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.5164992826398852, \"Count\": 2}, {\"Wave\": 3, \"Stance\": -1, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.1433632498819083, \"Count\": 0}, {\"Wave\": 3, \"Stance\": 0, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.3285309400094473, \"Count\": 1}, {\"Wave\": 3, \"Stance\": 1, \"Drug\": \"Molnupiravir\", \"Ratio\": 0.5281058101086443, \"Count\": 2}, {\"Wave\": 1, \"Stance\": -1, \"Drug\": \"Remdesivir\", \"Ratio\": 0.1517658617301825, \"Count\": 0}, {\"Wave\": 1, \"Stance\": 0, \"Drug\": \"Remdesivir\", \"Ratio\": 0.3914887015874657, \"Count\": 1}, {\"Wave\": 1, \"Stance\": 1, \"Drug\": \"Remdesivir\", \"Ratio\": 0.4567454366823517, \"Count\": 2}, {\"Wave\": 2, \"Stance\": -1, \"Drug\": \"Remdesivir\", \"Ratio\": 0.3301301181807329, \"Count\": 0}, {\"Wave\": 2, \"Stance\": 0, \"Drug\": \"Remdesivir\", \"Ratio\": 0.2364211531574549, \"Count\": 1}, {\"Wave\": 2, \"Stance\": 1, \"Drug\": \"Remdesivir\", \"Ratio\": 0.4334487286618121, \"Count\": 2}, {\"Wave\": 3, \"Stance\": -1, \"Drug\": \"Remdesivir\", \"Ratio\": 0.374629209562031, \"Count\": 0}, {\"Wave\": 3, \"Stance\": 0, \"Drug\": \"Remdesivir\", \"Ratio\": 0.1874018495899494, \"Count\": 1}, {\"Wave\": 3, \"Stance\": 1, \"Drug\": \"Remdesivir\", \"Ratio\": 0.4379689408480195, \"Count\": 2}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "\n",
    "plot1 = alt.Chart(df).mark_bar().encode(\n",
    "    x = \"Wave:O\",\n",
    "    y = \"Ratio:Q\",\n",
    "    color=alt.Color('Stance:N',scale = alt.Scale(domain=[-1,0,1],range=[\"#fd7f6f\",\"#cfd8dc\",\"#7e9ab9\"])),\n",
    "    opacity=alt.value(0.9),\n",
    "    column = \"Drug:N\"\n",
    ").properties(\n",
    "    width=60,\n",
    "    height=150\n",
    ")\n",
    "\n",
    "plot1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "9656b078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DRUG = \"hcq\" ## specify the dataset name.\n",
    "data_dir = \"../data/with_location/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1e91a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/enchome/anaconda3/envs/twee/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (13,15,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321040 tweets written to ../data/with_location/hcq.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "keywords_dict = {\"hcq\":\"ydroxych| hcq |plaqu |plaquenil|hydroquin|axemal\",\n",
    "                    \"ivermectin\": \"ivermectin|stromectol|soolantra|sklice\",\n",
    "                    \"remdesivir\": \"remdesivir|veklury\",\n",
    "                    \"molnupiravir\": \"molnupiravir|merck's drug|merck's pill|merck's antiviral\"}\n",
    "for drug, keywords in keywords_dict.items():\n",
    "    df = pd.read_csv(f\"{data_dir}{drug}.csv\")\n",
    "    # drug_df = df[df[\"full_text\"].str.contains(keywords, case=False)].drop_duplicates()\n",
    "    other_keys = keywords_dict.copy()\n",
    "    other_keys.pop(drug)\n",
    "    keys_for_other_drugs = \"|\".join(list(other_keys.values()))\n",
    "    df = df[~df.full_text.str.contains(keys_for_other_drugs, case=False)]\n",
    "    if not df.empty:\n",
    "        df.to_csv(f\"{data_dir}{drug}.csv\", index=False)\n",
    "        message = \"%i tweets written to %s\\n\"%(len(df), f\"{data_dir}{drug}.csv\")\n",
    "        print(message)\n",
    "    else:\n",
    "        print(\"Nothing left. Skipping...\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58b4d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3154c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 48 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "import re\n",
    "\n",
    "def clean_url(x):\n",
    "    return re.sub(r\"http\\S+\",\"\", x)\n",
    "\n",
    "df = pd.read_csv(f\"{data_dir}{DRUG}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6ca0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/enchome/anaconda3/envs/twee/lib/python3.9/site-packages/transformers/configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "# model_masked = AutoModelForSequenceClassification.from_pretrained(\"model/Twitter-drug-stance-bert-masked\").to(\"cuda:1\")  ## or masked \n",
    "# model_masked.eval()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"model/Twitter-drug-stance-bert\").to(\"cuda:1\")  ## or masked \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78c51bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(x):\n",
    "    tok = tokenizer(x,return_tensors = 'pt')\n",
    "    tok.to(\"cuda:1\")\n",
    "    \n",
    "    output = model(**tok)\n",
    "    predictions = torch.argmax(output.logits, dim=-1)\n",
    "    \n",
    "    return int(predictions[0])\n",
    "\n",
    "# def masked_infer(x):\n",
    "#     tok = tokenizer(x,return_tensors = 'pt')\n",
    "#     tok.to(\"cuda:1\")\n",
    "    \n",
    "#     output = model_masked(**tok)\n",
    "#     predictions = torch.argmax(output.logits, dim=-1)\n",
    "    \n",
    "#     return int(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d0f8106",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 292289/292289 [1:07:56<00:00, 71.70it/s] \n",
      "<ipython-input-29-9af531ff6ba8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"stance\"] = df.full_text.progress_apply(lambda x:infer(x))\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "df[\"stance\"] = df.full_text.progress_apply(lambda x:infer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "252f9a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 48 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/enchome/anaconda3/envs/twee/lib/python3.9/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1    151878\n",
       "-1    100320\n",
       " 0     40091\n",
       "Name: stance, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "\n",
    "def re_map(x):\n",
    "    if x==1: return -1\n",
    "    elif x==2: return 1\n",
    "    else: return 0\n",
    "df.stance = df.stance.parallel_apply(lambda x: re_map(x))\n",
    "df.stance.value_counts()  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d2f049c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"../data/final/{DRUG}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b50262",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddc78524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 95.25it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.42it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.72it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.22it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.24it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.03it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 98.86it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "tqdm.pandas()\n",
    "evaluation_dir = \"evaluation/\"\n",
    "os.makedirs(evaluation_dir, exist_ok=True)\n",
    "\n",
    "for drug in [\"hcq\",\"ivermectin\",\"molnupiravir\",\"remdesivir\"]:\n",
    "    df = pd.read_csv(f\"{data_dir}{drug}.csv\").sample(100, random_state=42)\n",
    "    df[\"stance\"] = df.full_text.apply(lambda x: infer(x))   \n",
    "    df[\"masked_prediction\"] = df.full_text.progress_apply(lambda x: masked_infer(x))\n",
    "    df[\"prediction\"] = df.full_text.progress_apply(lambda x: infer(x))\n",
    "    df.to_csv(f\"{evaluation_dir}{drug}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e6cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
